# -*- coding: utf-8 -*-
"""Hybrid Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nRc8npyDbyecoZdXlwv5mB_Tpe6AQMRc

# Setup & Import Library
"""

"""!pip install -q -U langchain-google-genai"""

import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

from IPython.display import display, HTML, clear_output
import ipywidgets as widgets
from difflib import get_close_matches

from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableSequence
from langchain_google_genai import ChatGoogleGenerativeAI

import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

import getpass, os

if "GOOGLE_API_KEY" not in os.environ:
    os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter your Google AI API key: ")

"""# Load Data"""

# Load Data dari URL
url = "https://drive.google.com/file/d/173cJmcwkC8dnlnvoXbDQ-1ZTVVAjtiMX/view?usp=drive_link"

# Deteksi file ID dari link Google Drive
match = re.search(r"/d/([a-zA-Z0-9_-]+)", url)

if match:
    file_id = match.group(1)
    url = f"https://drive.google.com/uc?export=download&id={file_id}"
else:
    raise ValueError("Link Google Drive tidak valid!")

print("Download URL:", url)

# Load CSV dari Google Drive
df = pd.read_csv(url)

print("Dataset berhasil dimuat! ‚úÖ")
print("Ukuran dataset:", df.shape)
print("\nBeberapa baris pertama:")
display(df.head())

print("\nInformasi kolom:")
df.info()

"""# Pre-Processing"""

# Data Cleaning
print("Cek missing values:")
display(df.isnull().sum())

# Handling Missing Value

# Isi atau hapus nilai kosong
df['Rating'] = df['Rating'].fillna(df['Rating'].mean())
df['ReviewCount'] = df['ReviewCount'].fillna(0)
df['Description'] = df['Description'].fillna('')
df['Tags'] = df['Tags'].fillna('')
df['Name'] = df['Name'].fillna('')
df['Category'] = df['Category'].fillna('Unknown')
df['Brand'] = df['Brand'].fillna('Unknown')

# Hapus duplikat berdasarkan ProdID
df = df.drop_duplicates(subset=['ProdID'])

print("\nData setelah cleaning:")
print(df.shape)
display(df.head())

# Pembersihan Rating
# Ganti rating 0 jadi NaN
df['Rating'] = df['Rating'].replace(0, np.nan)

# Isi NaN dengan rata-rata rating per produk (berdasarkan kolom 'ProductID' misalnya)
# Kalau tidak ada kolom 'ProductID', ganti dengan kolom yang mewakili produk unik
df['Rating'] = df.groupby('Brand')['Rating'].transform(lambda x: x.fillna(x.mean()))

# Kalau masih ada NaN (misal karena seluruh rating produk itu 0 sebelumnya), isi dengan rata-rata global
df['Rating'] = df['Rating'].fillna(df['Rating'].mean())

# Pemeriksaan ulang
print("\nCek missing values setelah cleaning:")
display(df.isnull().sum())

"""# Exploratory Data Analysis (EDA)"""

# Exploratory Data Analysis (EDA)
print("Informasi Dataset Setelah Cleaning:")
print("Jumlah Baris:", df.shape[0])
print("Jumlah Kolom:", df.shape[1])
print("\nTipe Data Tiap Kolom:")
display(df.dtypes)

print("\nCek Nilai Kosong:")
display(df.isnull().sum())

print("\nPreview Data:")
display(df.head(3))

# --- Lanjutkan ke EDA ---
plt.figure(figsize=(6,4))
sns.histplot(df['Rating'], bins=20, kde=True)
plt.title("Distribusi Rating Produk")
plt.xlabel("Rating")
plt.ylabel("Frekuensi")
plt.show()

print("Rata-rata rating:", round(df['Rating'].mean(), 2))
print("Rating tertinggi:", df['Rating'].max())
print("Rating terendah:", df['Rating'].min())

# Top 10 kategori
plt.figure(figsize=(8,4))
df['Category'].value_counts().head(10).plot(kind='barh', color='skyblue')
plt.title("Top 10 Product Categories")
plt.xlabel("Jumlah Produk")
plt.ylabel("Category")
plt.show()

# Distribusi Jumlah Review
plt.figure(figsize=(6,4))
sns.histplot(df['ReviewCount'], bins=30, kde=True)
plt.title("Distribusi Jumlah Review Produk")
plt.xlabel("Jumlah Review")
plt.ylabel("Frekuensi")
plt.show()

print("Rata-rata review:", round(df['ReviewCount'].mean(), 2))
print("Maksimum review:", df['ReviewCount'].max())

# Korelasi Antar Nilai Numerik
plt.figure(figsize=(5,3))
sns.heatmap(df[['Rating','ReviewCount']].corr(), annot=True, cmap='Blues')
plt.title("Korelasi antar variabel numerik")
plt.show()

"""# Feature Engineering"""

# FEATURE ENGINEERING
# Cek & isi missing value penting
df['Brand'] = df['Brand'].fillna('Unknown')
df['Category'] = df['Category'].fillna('Miscellaneous')
df['Rating'] = df['Rating'].fillna(df['Rating'].mean())
df['ReviewCount'] = df['ReviewCount'].fillna(0)
df['Description'] = df['Description'].fillna('')
df['Tags'] = df['Tags'].fillna('')
df['Name'] = df['Name'].fillna('')

# Gabungkan semua kolom teks jadi satu
df['text_features'] = (
    df['Name'] + ' ' +
    df['Description'] + ' ' +
    df['Tags'] + ' ' +
    df['Brand'] + ' ' +
    df['Category']
)

# TF-IDF vectorization untuk fitur teks
vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
tfidf_matrix = vectorizer.fit_transform(df['text_features'])
print("TF-IDF matrix:", tfidf_matrix.shape)

# Normalisasi nilai numerik (rating & review count)
scaler = MinMaxScaler()
df[['Rating_scaled', 'ReviewCount_scaled']] = scaler.fit_transform(
    df[['Rating', 'ReviewCount']]
)

# Ringkasan hasil
print("\nRingkasan Kolom Baru:")
print(df[['Rating_scaled','ReviewCount_scaled']].head(3))
print("\nKolom dataset:", list(df.columns))
print("\nCek 2 data acak:")
display(df.sample(5))

"""# Modelling"""

# HYBRID RECOMMENDER SYSTEM (FIXED)
# Pastikan index df berurutan mulai dari 0
df = df.reset_index(drop=True)

# Ubah skala ReviewCount supaya distribusinya lebih seimbang
df['review_log'] = np.log1p(df['ReviewCount'])
df['review_norm'] = df['review_log'] / df['review_log'].max()

# Scaling numeric features
scaler = MinMaxScaler()
df['Rating_scaled'] = scaler.fit_transform(df[['Rating']])
df['ReviewCount_scaled'] = scaler.fit_transform(df[['ReviewCount']])

# TF-IDF untuk konten produk
vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
tfidf_matrix = vectorizer.fit_transform(
    df['Name'].fillna('') + ' ' +
    df['Description'].fillna('') + ' ' +
    df['Tags'].fillna('') + ' ' +
    df['Category'].fillna('')
)

# Content-based similarity
content_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Numeric similarity
num_features = df[['Rating_scaled', 'ReviewCount_scaled']].values
numeric_sim = cosine_similarity(num_features, num_features)

# Hybrid similarity
hybrid_sim = 0.4 * content_sim + 0.6 * numeric_sim

"""# Evaluasi Rata-Rata"""

# Evaluasi rata-rata similarity untuk seluruh produk
results = []
for idx, row in df.iterrows():
    product_name = row['Name']
    sim_scores = list(enumerate(hybrid_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:6]
    avg_sim = np.mean([s[1] for s in sim_scores])
    results.append({
        'Product': product_name,
        'Brand': row['Brand'],
        'Category': row['Category'],
        'Average_Similarity': avg_sim
    })

df_similarity_eval = pd.DataFrame(results).sort_values(by='Average_Similarity', ascending=False)
display(df_similarity_eval.head(10))

# Pastikan df dan hybrid_sim punya ukuran sama
print("Jumlah produk di df:", len(df))
print("Ukuran hybrid_sim:", hybrid_sim.shape)

# Kalau berbeda, potong biar sejajar
if len(df) != hybrid_sim.shape[0]:
    df = df.iloc[:hybrid_sim.shape[0]].reset_index(drop=True)

# Evaluasi rata-rata kesamaan untuk seluruh produk
results = []

for idx in range(hybrid_sim.shape[0]):
    product = df.iloc[idx]['Name']
    sim_scores = list(enumerate(hybrid_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:6]  # 5 produk paling mirip
    avg_sim = np.mean([s[1] for s in sim_scores])
    results.append({
        'Product': product,
        'Brand': df.iloc[idx]['Brand'],
        'Category': df.iloc[idx]['Category'],
        'Average_Similarity': avg_sim
    })

# Buat tabel hasil
df_similarity_eval = pd.DataFrame(results).sort_values(by='Average_Similarity', ascending=False)

# Tampilkan tabel 10 teratas
print("üîπ Top 10 Produk dengan Rata-rata Kemiripan Tertinggi (Hybrid Model):")
display(df_similarity_eval.head(10))

# (Opsional) Tampilkan 10 produk dengan kemiripan terendah
print("\nüîπ 10 Produk dengan Rata-rata Kemiripan Terendah:")
display(df_similarity_eval.tail(10))

# Statistik global
print("\nüìä Statistik Keseluruhan:")
print(f"Rata-rata keseluruhan similarity: {df_similarity_eval['Average_Similarity'].mean():.4f}")
print(f"Nilai maksimum similarity: {df_similarity_eval['Average_Similarity'].max():.4f}")
print(f"Nilai minimum similarity: {df_similarity_eval['Average_Similarity'].min():.4f}")

"""# Visualisasi"""

# Visualisasi Hybrid Recommendation
# Evaluasi Kesamaan Produk (OPI Parameter)
def evaluate_recommendations(product_name, n=5):
    if product_name not in df['Name'].values:
        return f"Produk '{product_name}' tidak ditemukan."

    idx = df[df['Name'] == product_name].index[0]
    sim_scores = list(enumerate(hybrid_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:n+1]

    # Hitung rata-rata similarity
    avg_sim = np.mean([s[1] for s in sim_scores])

    # Ambil rekomendasi
    recommended = df.iloc[[i[0] for i in sim_scores]][['Name','Brand','Category','Rating','ReviewCount']]

    print(f"üîπ Produk acuan: {product_name}")
    print(f"üîπ Rata-rata similarity: {avg_sim:.3f}")
    return recommended

# Contoh evaluasi
sample_product = df['Name'].iloc[0]
recommended = evaluate_recommendations(sample_product, n=5)
display(recommended)

# Heatmap Kemiripan Produk (Visualisasi)
plt.figure(figsize=(10,6))
sample_indices = range(10)
sample_names = df['Name'].iloc[sample_indices]
sns.heatmap(
    hybrid_sim[np.ix_(sample_indices, sample_indices)],
    xticklabels=sample_names,
    yticklabels=sample_names,
    cmap='YlGnBu'
)
plt.title(" Korelasi Kemiripan Antar Produk (Hybrid Similarity)")
plt.xticks(rotation=90)
plt.show()

# Analisis Popularitas (Bonus Insight)
top_popular = df.sort_values(by=['Rating','ReviewCount'], ascending=False).head(10)
plt.figure(figsize=(8,4))
sns.barplot(data=top_popular, x='Rating', y='Name')
plt.title("Top 10 Produk dengan Rating & Review Tertinggi")
plt.show()

"""# UI"""

# Deployment Hybrid Recommendation System (UI + CLI Mode)
# Fungsi rekomendasi
def hybrid_recommend(product_name, n=5):
    product_name = product_name.strip().lower()
    df['Name_norm'] = df['Name'].str.strip().str.lower()

    # Cari produk mirip
    if product_name not in df['Name_norm'].values:
        matches = df[df['Name_norm'].str.contains(product_name, case=False, na=False)]
        if len(matches) == 0:
            closest = get_close_matches(product_name, df['Name_norm'], n=1, cutoff=0.4)
            if not closest:
                return f"‚ùå Produk '{product_name}' tidak ditemukan di dataset."
            product_name = closest[0]
            print(f"üîç Produk tidak ditemukan persis. Menampilkan hasil mirip: {product_name}")
        else:
            product_name = matches['Name_norm'].iloc[0]
            print(f"üîç Produk mirip ditemukan: {product_name}")

    idx = df[df['Name_norm'] == product_name].index[0]
    sim_scores = list(enumerate(hybrid_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:n+20]  # ambil lebih banyak dulu

    results = df.iloc[[i[0] for i in sim_scores]].copy()
    results['similarity'] = [s[1] for s in sim_scores]

    # Normalisasi rating & review agar 0-1
    results['rating_norm'] = (results['Rating'] - results['Rating'].min()) / (results['Rating'].max() - results['Rating'].min())
    results['review_norm'] = (results['ReviewCount'] - results['ReviewCount'].min()) / (results['ReviewCount'].max() - results['ReviewCount'].min())

    # Skor akhir = kombinasi similarity + rating + review count
    results['final_score'] = (
      0.4 * results['similarity'] +
      0.3 * results['rating_norm'] +
      0.3 * results['review_norm']
    )

    # Urutkan berdasarkan final_score
    results = results.sort_values('final_score', ascending=False)

    # Ambil top-n
    recommended = results[['Name','Brand','Category','Rating','ReviewCount','final_score','Description']].head(n)
    return recommended

# ---- Mode UI (Text Box Colab) ----
input_box = widgets.Text(
    placeholder='Ketik nama produk...',
    description='Produk:',
    layout=widgets.Layout(width='400px')
)
output_area = widgets.Output()
exit_button = widgets.Button(description="Exit", button_style='danger')
clear_button = widgets.Button(description="Clear Output", button_style='warning')

# Event handler
def on_submit(change):
    with output_area:
        clear_output()
        product_name = change['new']
        if not product_name:
            print("Masukkan nama produk untuk melihat rekomendasi.")
            return
        result = hybrid_recommend(product_name, n=10)
        if isinstance(result, str):
            print(result)
        else:
            display(result)

def on_exit_clicked(b):
  with output_area:
      clear_output()
      print("üëã Sistem rekomendasi dihentikan. Terima kasih!")

def on_clear_clicked(b):
  with output_area:
      clear_output()
      print("üßπ Output dibersihkan. Silakan ketik nama produk lagi.")

# Hubungkan event
input_box.observe(on_submit, names='value')
exit_button.on_click(on_exit_clicked)
clear_button.on_click(on_clear_clicked)

# Tampilkan interface
# display(HTML("<h3>üõçÔ∏è Hybrid Product Recommender</h3><p>Ketik nama produk untuk melihat rekomendasi miripnya.</p>"))
# display(input_box, widgets.HBox([clear_button, exit_button]), output_area)

"""# Evaluasi LLM"""

# Schema output
class HybridEvaluation(BaseModel):
    score: int = Field(..., description="Skor penilaian 1‚Äì10")
    description: str = Field(..., description="Deskripsi singkat tentang kualitas rekomendasi")
    reasons: list[str] = Field(..., description="Alasan penilaian")
    summary: str = Field(..., description="Ringkasan keseluruhan evaluasi hybrid")

parser = PydanticOutputParser(pydantic_object=HybridEvaluation)

# Prompt evaluator
prompt = ChatPromptTemplate.from_messages([
    ("system", "Kamu adalah evaluator untuk sistem rekomendasi hybrid."),
    ("human", """
Berikut adalah hasil rekomendasi hybrid:

{rekomendasi}

Tolong lakukan evaluasi dengan format berikut:

1. score = nilai 1‚Äì10 untuk kualitas keseluruhan rekomendasi.
2. description = deskripsi singkat (1 paragraf) tentang impresi utama dari hasil rekomendasi.
3. reasons = daftar alasan evaluasi dalam bentuk bullet/poin.
4. summary = ringkasan akhir kualitas hybrid system secara keseluruhan (1 paragraf).

Output HARUS mengikuti format:
{format_instructions}
"""),
])

# Model Gemini
eval_model = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0
)

# Pipeline
evaluation_chain = prompt | eval_model | parser

# Fungsi
def evaluate_recommendation(df_rekom):
    rekom_json = df_rekom.astype(str).to_dict(orient="records")  # FIX serialization

    result = evaluation_chain.invoke({
        "rekomendasi": rekom_json,
        "format_instructions": parser.get_format_instructions()
    })

    return result

def show_evaluation_ui(evaluation: HybridEvaluation):
    # Extract fields
    score = evaluation.score
    description = evaluation.description
    reasons = evaluation.reasons
    summary = evaluation.summary

    # Score color
    if score >= 8:
        score_color = "#4CAF50"   # green
    elif score >= 5:
        score_color = "#FFC107"   # yellow
    else:
        score_color = "#F44336"   # red

    # Build reasons list HTML
    reasons_html = "".join([f"<li>{r}</li>" for r in reasons])

    html = f"""
    <div style="
        border-radius: 12px;
        border: 1px solid #ddd;
        padding: 20px;
        margin-top: 10px;
        background: #808080;
        font-family: 'Segoe UI', sans-serif;
    ">
        <h2 style="margin-top:0;">üìä Hybrid Recommendation Evaluation</h2>

        <h3 style="color:{score_color}; margin-bottom:5px;">
            ‚≠ê Score: {score}/10
        </h3>

        <p><strong>Description:</strong></p>
        <p style="margin-left: 10px;">{description}</p>

        <p><strong>Reasons:</strong></p>
        <ul style="margin-left: 20px;">
            {reasons_html}
        </ul>

        <p><strong>Summary:</strong></p>
        <p style="margin-left: 10px;">{summary}</p>
    </div>
    """

    clear_output(wait=True)
    display(HTML(html))

df_rekom = df.head(5)
result = evaluate_recommendation(df_rekom)
# show_evaluation_ui(result)

show_evaluation_ui(result)

# Tampilkan interface
display(HTML("<h3>üõçÔ∏è Hybrid Product Recommender</h3><p>Ketik nama produk untuk melihat rekomendasi miripnya.</p>"))
display(input_box, widgets.HBox([clear_button, exit_button]), output_area)

"""# ADD"""

# LLM Query Interpreter (Gemini) - Pydantic schema + prompt
class QueryInterpretation(BaseModel):
    product_name: str = Field(..., description="Nama produk atau kata kunci yang paling relevan")
    keywords: list[str] = Field([], description="Keywords relevan")

parser_q = PydanticOutputParser(pydantic_object=QueryInterpretation)

prompt_q = ChatPromptTemplate.from_messages([
    ("system", "Kamu adalah assistant yang mengubah query pengguna menjadi nama produk atau kata kunci yang cocok untuk dataset produk."),
    ("human", "User input: {query}\n\nBerikan JSON dengan fields 'product_name' (string) dan 'keywords' (list of strings).")
])

llm_q = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

query_chain = prompt_q | llm_q | parser_q


def interpret_query_with_llm(q):
    try:
        out = query_chain.invoke({"query": q})
        return out.product_name
    except Exception as e:
        logger.warning(f"LLM interpret error: {e} ‚Äî falling back to raw query")
        return q

# LLM Evaluator (Pydantic) for recommendations
class CFEvaluation(BaseModel):
    score: int = Field(..., description="Skor 1-10")
    description: str = Field(..., description="Deskripsi singkat")
    reasons: list[str] = Field(..., description="Daftar alasan")
    summary: str = Field(..., description="Ringkasan akhir")

parser_eval = PydanticOutputParser(pydantic_object=CFEvaluation)

prompt_eval = ChatPromptTemplate.from_messages([
    ("system", "Kamu adalah evaluator kualitas rekomendasi produk."),
    ("human",
     "Berikut daftar rekomendasi (JSON array):\n{rekom}\n\nGunakan format Pydantic berikut:\n{format_instructions}")
])

llm_eval = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

def evaluate_recommendation_with_llm(df_rekom):
    try:
        rekom_str = df_rekom.to_string(index=False)

        chain = prompt_eval | llm_eval | parser_eval

        inputs = {
            "rekom": rekom_str,
            "format_instructions": parser_eval.get_format_instructions()
        }

        result = chain.invoke(inputs)
        return result

    except Exception as e:
        logging.error(f"LLM evaluation error: {e}")
        return None

# RECOMMENDER ENGINE (NO ERROR)

# Fungsi mencari rekomendasi berdasarkan hybrid similarity
def get_recommendations(query, top_n=5):
    # Cari produk yang mengandung query
    mask = df['Name'].str.contains(query, case=False, na=False)
    if not mask.any():
        return pd.DataFrame()

    idx = df[mask].index[0]  # ambil produk pertama yang cocok

    sim_scores = list(enumerate(hybrid_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1: top_n+1]

    result = pd.DataFrame({
        "Name": df.iloc[[i for i, s in sim_scores]]['Name'].values,
        "Brand": df.iloc[[i for i, s in sim_scores]]['Brand'].values,
        "Category": df.iloc[[i for i, s in sim_scores]]['Category'].values,
        "similarity": [s for i, s in sim_scores]
    })

    return result

# METRICS
metrics = {
    "avg_topk_similarity": df_similarity_eval["Average_Similarity"].mean(),
    "global_mean_similarity": df_similarity_eval["Average_Similarity"].mean()
}

# Dummy LLM interpreter supaya tidak error
def interpret_query_with_llm(text):
    return text  # tidak ada LLM ‚Üí kembalikan text asli

# Dummy evaluator supaya tidak error
class EvalResult:
    def __init__(self, score, description, reasons, summary):
        self.score = score
        self.description = description
        self.reasons = reasons
        self.summary = summary

def evaluate_recommendation_with_llm(dfrec):
    return EvalResult(
        score=8,
        description="Rekomendasi cukup relevan.",
        reasons=["Cocok kategori", "Deskripsi serupa"],
        summary="Rekomendasi sudah baik namun masih bisa ditingkatkan."
    )

# UI SECTION (FIXED)
product_input = widgets.Text(
    placeholder="Masukkan nama / jenis produk",
    description="Produk:",
    layout=widgets.Layout(width='600px')
)

topn_input = widgets.IntSlider(
    value=5, min=1, max=20, step=1, description="Top N"
)

use_llm_checkbox = widgets.Checkbox(
    value=True, description="Gunakan LLM interpreter?"
)

btn_recommend = widgets.Button(description="Run Recommendation", button_style='success')
btn_metrics = widgets.Button(description="Show Metrics", button_style='info')
btn_evaluate = widgets.Button(description="Evaluate with LLM", button_style='warning')

out = widgets.Output(layout={'border': '1px solid black'})

current_rekom = None


def on_run_recommend(b):
    global current_rekom
    with out:
        clear_output()
        raw_query = product_input.value.strip()
        if raw_query == "":
            print("‚ùå Masukkan nama produk terlebih dahulu.")
            return

        if use_llm_checkbox.value:
            interpreted = interpret_query_with_llm(raw_query)
            print(f"Input user: {raw_query}")
            print(f"Interpreted (LLM): {interpreted}\n")
        else:
            interpreted = raw_query

        recs = get_recommendations(interpreted, topn_input.value)

        if recs.empty:
            print("‚ö†Ô∏è Tidak ada rekomendasi ditemukan.")
            current_rekom = None
            return

        display(recs)
        current_rekom = recs.copy()

        print(f"\nRata-rata similarity: {recs['similarity'].mean():.4f}")
        print(f"Rata-rata top-k similarity dataset: {metrics['avg_topk_similarity']:.4f}")


def on_show_metrics(b):
    with out:
        clear_output()
        print("=== Similarity Metrics (dataset) ===")
        print(f"Rata-rata top-k similarity: {metrics['avg_topk_similarity']:.4f}")
        print(f"Rata-rata global similarity: {metrics['global_mean_similarity']:.4f}")


def on_evaluate(b):
    with out:
        clear_output()
        if current_rekom is None:
            print("‚ùå Tidak ada rekomendasi untuk dievaluasi.")
            return

        eval_res = evaluate_recommendation_with_llm(current_rekom)

        print("‚úÖ Evaluasi selesai.\n")
        display(HTML(f"<h3>Score: {eval_res.score}/10</h3>"))
        display(HTML(f"<p><b>Description:</b> {eval_res.description}</p>"))
        display(HTML("<p><b>Reasons:</b></p><ul>" +
                     "".join([f"<li>{r}</li>" for r in eval_res.reasons]) +
                     "</ul>"))
        display(HTML(f"<p><b>Summary:</b> {eval_res.summary}</p>"))


btn_recommend.on_click(on_run_recommend)
btn_metrics.on_click(on_show_metrics)
btn_evaluate.on_click(on_evaluate)

ui = widgets.VBox([
    widgets.HTML("<h2>Item-based CF + LLM Integrated Recommender</h2>"),
    product_input,
    widgets.HBox([topn_input, use_llm_checkbox]),
    widgets.HBox([btn_recommend, btn_metrics, btn_evaluate]),
    out
])

display(ui)